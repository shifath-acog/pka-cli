{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08cd9069",
   "metadata": {
    "papermill": {
     "duration": 0.006312,
     "end_time": "2025-07-17T10:29:35.695835",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.689523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conformer Generation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971aa7f-5c76-4f35-9c81-4116d9657d34",
   "metadata": {
    "papermill": {
     "duration": 0.006373,
     "end_time": "2025-07-17T10:29:35.708596",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.702223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 1: Input Smile and Reference Conformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d501701-5206-48cd-b7da-e90f6caf7b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:35.722825Z",
     "iopub.status.busy": "2025-07-17T10:29:35.722355Z",
     "iopub.status.idle": "2025-07-17T10:29:35.725169Z",
     "shell.execute_reply": "2025-07-17T10:29:35.724678Z"
    },
    "papermill": {
     "duration": 0.01109,
     "end_time": "2025-07-17T10:29:35.725981",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.714891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Capture the start time\n",
    "start_time: float = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c7779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:35.739563Z",
     "iopub.status.busy": "2025-07-17T10:29:35.739144Z",
     "iopub.status.idle": "2025-07-17T10:29:35.741760Z",
     "shell.execute_reply": "2025-07-17T10:29:35.741305Z"
    },
    "papermill": {
     "duration": 0.01021,
     "end_time": "2025-07-17T10:29:35.742542",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.732332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add a folder to Python's import path\n",
    "sys.path.append('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a545a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:35.756111Z",
     "iopub.status.busy": "2025-07-17T10:29:35.755635Z",
     "iopub.status.idle": "2025-07-17T10:29:36.541910Z",
     "shell.execute_reply": "2025-07-17T10:29:36.541267Z"
    },
    "papermill": {
     "duration": 0.794602,
     "end_time": "2025-07-17T10:29:36.543489",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.748887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from atk_conformer_generation_pipeline.utils import *\n",
    "from atk_conformer_generation_pipeline.variables import *\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df80ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:36.558431Z",
     "iopub.status.busy": "2025-07-17T10:29:36.557890Z",
     "iopub.status.idle": "2025-07-17T10:29:36.833913Z",
     "shell.execute_reply": "2025-07-17T10:29:36.833295Z"
    },
    "papermill": {
     "duration": 0.284335,
     "end_time": "2025-07-17T10:29:36.834937",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.550602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Change the dir to /work\n",
    "os.chdir(\"/work\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b42bf",
   "metadata": {
    "papermill": {
     "duration": 0.006441,
     "end_time": "2025-07-17T10:29:36.848279",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.841838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Change the below variables accordingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac382af3-999f-448f-b2aa-9dbc8156c0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:36.879229Z",
     "iopub.status.busy": "2025-07-17T10:29:36.878804Z",
     "iopub.status.idle": "2025-07-17T10:29:36.881685Z",
     "shell.execute_reply": "2025-07-17T10:29:36.881221Z"
    },
    "papermill": {
     "duration": 0.010598,
     "end_time": "2025-07-17T10:29:36.882510",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.871912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.chdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b3690-cdda-4863-8df0-a2d88dc4055b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:36.896209Z",
     "iopub.status.busy": "2025-07-17T10:29:36.895747Z",
     "iopub.status.idle": "2025-07-17T10:29:37.169761Z",
     "shell.execute_reply": "2025-07-17T10:29:37.169127Z"
    },
    "papermill": {
     "duration": 0.281823,
     "end_time": "2025-07-17T10:29:37.170713",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.888890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba3694-7eed-4a2d-bc09-e0df8c6e5b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.185222Z",
     "iopub.status.busy": "2025-07-17T10:29:37.184688Z",
     "iopub.status.idle": "2025-07-17T10:29:37.187784Z",
     "shell.execute_reply": "2025-07-17T10:29:37.187313Z"
    },
    "papermill": {
     "duration": 0.011069,
     "end_time": "2025-07-17T10:29:37.188581",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.177512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "# set the maximum depth of the Python interpreter stack. This stack depth is crucial for recursive function calls, \n",
    "# as it limits how deep the recursion can go before causing a RecursionError."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439e673",
   "metadata": {
    "papermill": {
     "duration": 0.006304,
     "end_time": "2025-07-17T10:29:37.201302",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.194998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Importing the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61799b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.214983Z",
     "iopub.status.busy": "2025-07-17T10:29:37.214548Z",
     "iopub.status.idle": "2025-07-17T10:29:37.586264Z",
     "shell.execute_reply": "2025-07-17T10:29:37.585635Z"
    },
    "papermill": {
     "duration": 0.379989,
     "end_time": "2025-07-17T10:29:37.587665",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.207676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import csv\n",
    "from typing import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6978d0c",
   "metadata": {
    "papermill": {
     "duration": 0.008453,
     "end_time": "2025-07-17T10:29:41.683806",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.675353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 7: Geometry optimization of neutral conformers using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752a24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:41.701913Z",
     "iopub.status.busy": "2025-07-17T10:29:41.701335Z",
     "iopub.status.idle": "2025-07-17T10:29:41.995351Z",
     "shell.execute_reply": "2025-07-17T10:29:41.994561Z"
    },
    "papermill": {
     "duration": 0.304667,
     "end_time": "2025-07-17T10:29:41.996886",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.692219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python /app/dft_main.py DFT {cluster_reps_dir} {dielectric_value} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7d5b9-6e34-42e0-866b-1135a2938ceb",
   "metadata": {
    "papermill": {
     "duration": 0.008539,
     "end_time": "2025-07-17T10:29:42.014722",
     "exception": false,
     "start_time": "2025-07-17T10:29:42.006183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 9: Geometry optimization of charged conformers using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e532a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:42.058769Z",
     "iopub.status.busy": "2025-07-17T10:29:42.058304Z",
     "iopub.status.idle": "2025-07-17T10:29:42.303379Z",
     "shell.execute_reply": "2025-07-17T10:29:42.302551Z"
    },
    "papermill": {
     "duration": 0.255024,
     "end_time": "2025-07-17T10:29:42.304247",
     "exception": true,
     "start_time": "2025-07-17T10:29:42.049223",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basis and XC\n",
    "basis_sets = ['aug-cc-pVDZ']\n",
    "xc_functionals = ['M06-2X']  # Add more if needed\n",
    "\n",
    "for basis in basis_sets:\n",
    "        for xc in xc_functionals:\n",
    "             # Sanitize names for filename safety\n",
    "            basis_tag = basis.replace(\"(\", \"\").replace(\")\", \"\").replace(\"*\", \"\").replace(\"+\", \"\").replace(\"/\", \"-\").replace(\" \", \"\")\n",
    "            xc_tag = xc.replace(\"(\", \"\").replace(\")\", \"\").replace(\"*\", \"\").replace(\"+\", \"\").replace(\"/\", \"-\").replace(\" \", \"\")\n",
    "\n",
    "# Get list of SDF files\n",
    "sdf_files = sorted(glob.glob(os.path.join(cluster_reps_dir, \"*.sdf\")))\n",
    "\n",
    "# Loop over each SDF file\n",
    "for sdf_path in sdf_files:\n",
    "    sdf_filename = os.path.basename(sdf_path)\n",
    "    sdf_stem = os.path.splitext(sdf_filename)[0]  # Remove .sdf extension\n",
    "\n",
    "    for basis in basis_sets:\n",
    "        for xc in xc_functionals:\n",
    "            \n",
    "            # Output file names\n",
    "            new_filename = f\"{sdf_stem}_{basis_tag}_{xc_tag}.sdf\"\n",
    "            new_filepath = os.path.join(cluster_reps_dir, new_filename)\n",
    "            shutil.copy(sdf_path, new_filepath)\n",
    "            print(\"Renamed output will be:\", new_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df22ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T18:47:51.833034Z",
     "iopub.status.busy": "2025-05-22T18:47:51.832369Z",
     "iopub.status.idle": "2025-05-22T18:47:52.174441Z",
     "shell.execute_reply": "2025-05-22T18:47:52.173730Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define base paths\n",
    "base_dir = f\"/work/{output_dir}/cluster_rep_conformers\"\n",
    "treated_dir = os.path.join(base_dir, \"treated\")\n",
    "\n",
    "# Run the external Python script\n",
    "subprocess.run([\n",
    "    \"python\",\n",
    "    \"/app/ionization_tool_with_ranking/main.py\",\n",
    "    base_dir\n",
    "], check=True)\n",
    "\n",
    "# Move all .sdf files from treated/ to base_dir\n",
    "sdf_files = glob.glob(os.path.join(treated_dir, \"*.sdf\"))\n",
    "for file_path in sdf_files:\n",
    "    shutil.move(file_path, base_dir)\n",
    "\n",
    "# Remove the treated directory\n",
    "shutil.rmtree(treated_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abca850",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /app/dft_main.py DFT_DEPROTO {cluster_reps_dir} {dielectric_value} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa20541-9f07-495a-82ec-352a68c06a68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Step 10: Accumulating DFT data and Writing the CSV for pKa Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6634319",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe_from_xyz_files(folder_path):\n",
    "    \"\"\"\n",
    "    Creates a pandas DataFrame from .xyz files in a given folder,\n",
    "    extracting Basis, XC, and energy.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the .xyz files.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with 'file name', 'Basis', 'XC', and 'energy' columns.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Updated Regex to match the filename pattern and capture Basis and XC\n",
    "    # This regex is more robust to handle basis sets and XC functionals\n",
    "    # that may contain hyphens, numbers, or specific characters.\n",
    "    # It assumes the structure is:\n",
    "    # rep_of_cluster_N_BASIS_XC_optional_treatment.xyz\n",
    "    filename_pattern = re.compile(\n",
    "        r\"rep_of_cluster_\\d+_([a-zA-Z0-9\\-]+)_([a-zA-Z0-9\\-]+)(?:_deprotonated|_protonated)?\\.xyz\"\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".xyz\"):\n",
    "            match = filename_pattern.match(filename)\n",
    "            if match:\n",
    "                basis = match.group(1)\n",
    "                xc = match.group(2)\n",
    "\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        f.readline()  # Skip the first line (number of atoms)\n",
    "                        energy_line = f.readline().strip()\n",
    "\n",
    "                        energy = None\n",
    "                        try:\n",
    "                            energy = float(energy_line)\n",
    "                        except ValueError:\n",
    "                            energy_match = re.search(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", energy_line)\n",
    "                            if energy_match:\n",
    "                                energy = float(energy_match.group(0))\n",
    "                            else:\n",
    "                                print(f\"Could not extract energy from line: '{energy_line}' in file: {filename}\")\n",
    "\n",
    "                        data.append({\n",
    "                            'file name': filename,\n",
    "                            'Basis': basis,\n",
    "                            'XC': xc,\n",
    "                            'energy': energy\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"Filename pattern did not match for: {filename}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# --- How to use the function ---\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_dataframe_from_xyz_files(cluster_reps_dir)\n",
    "\n",
    "\n",
    "df.head(15)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cb9ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---\n",
    "# Step 1: Extract the Common Prefix\n",
    "def extract_prefix(filename):\n",
    "    match = re.match(r'(rep_of_cluster_\\d+_aug-cc-pVDZ_M06-2X)', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return filename\n",
    "\n",
    "df['prefix'] = df['file name'].apply(extract_prefix)\n",
    "\n",
    "# ---\n",
    "# Step 2: Group and Process to Assign Custom Names, including Basis and XC\n",
    "\n",
    "output_rows = []\n",
    "for prefix, group in df.groupby('prefix'):\n",
    "    row_dict = {'Prefix': prefix}\n",
    "    \n",
    "    # Get Basis and XC from the first row of the group (they should be constant within the group)\n",
    "    # Using .iloc[0] is safe here because each group will have at least one row\n",
    "    row_dict['Basis'] = group['Basis'].iloc[0]\n",
    "    row_dict['XC'] = group['XC'].iloc[0]\n",
    "\n",
    "    # Initialize placeholders for the new columns\n",
    "    row_dict['Filename_original'] = None\n",
    "    row_dict['Energy_original'] = None\n",
    "    row_dict['Filename_acid_treated'] = None\n",
    "    row_dict['Energy_acid_treated'] = None\n",
    "    row_dict['Filename_base_treated'] = None\n",
    "    row_dict['Energy_base_treated'] = None\n",
    "\n",
    "\n",
    "    for _, entry in group.iterrows():\n",
    "        filename = entry['file name']\n",
    "        energy = entry['energy']\n",
    "\n",
    "        if '_deprotonated' in filename:\n",
    "            row_dict['Filename_deprotonated'] = filename\n",
    "            row_dict['Energy_deprotonated'] = energy\n",
    "        elif '_protonated' in filename:\n",
    "            row_dict['Filename_protonated'] = filename\n",
    "            row_dict['Energy_protonated'] = energy\n",
    "        else:\n",
    "            # Assuming files without _acid_treat or _base_treat are the 'original'\n",
    "            row_dict['Filename_original'] = filename\n",
    "            row_dict['Energy_original'] = energy\n",
    "            \n",
    "    output_rows.append(row_dict)\n",
    "\n",
    "result_df = pd.DataFrame(output_rows)\n",
    "\n",
    "# Reorder columns for better readability\n",
    "# Ensure all these columns exist in result_df before attempting to reorder\n",
    "desired_columns = ['Prefix', 'Basis', 'XC',\n",
    "                   'Filename_original', 'Energy_original',\n",
    "                   'Filename_deprotonated', 'Energy_deprotonated',\n",
    "                   'Filename_protonated', 'Energy_protonated']\n",
    "\n",
    "# Filter for only the columns that actually exist in result_df to avoid errors\n",
    "existing_columns = [col for col in desired_columns if col in result_df.columns]\n",
    "result_df = result_df[existing_columns]\n",
    "\n",
    "\n",
    "#print\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02983554-0efb-4ad7-afba-4d8755aac0d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Step 11: Data analysis and pKa Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e7287-08f9-4e46-9d38-587dd275e0ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df['E_proton (acidic)']=pKa_EXP*1.36574 +(result_df['Energy_original'] -result_df['Energy_deprotonated'])\n",
    "if 'Energy_protonated' in result_df.columns:\n",
    "    result_df['E_proton (basic)']=pKa_EXP*1.36574 -(result_df['Energy_original'] -result_df['Energy_protonated'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734caa6-deb6-45d4-835e-874293e3fb28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = 298  # Temperature in Kelvin\n",
    "k_B = 0.0019872041  # Boltzmann constant in kcal/mol·K\n",
    "\n",
    "E_shifted = result_df['Energy_original'] - result_df['Energy_original'].min()  # shift energies so lowest is 0\n",
    "weights = np.exp(-E_shifted / (k_B * T))\n",
    "\n",
    "#Boltzmann Probabilities\n",
    "result_df['Weights'] = weights / np.sum(weights)\n",
    "\n",
    "if 'Energy_deprotonated' in result_df.columns and 'Energy_protonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original', 'Energy_deprotonated','E_proton (acidic)','Energy_protonated', 'E_proton (basic)', 'Weights' ]]\n",
    "\n",
    "elif 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original', 'Energy_deprotonated','E_proton (acidic)','Weights' ]]\n",
    "\n",
    "elif 'Energy_protonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original','Energy_protonated', 'E_proton (basic)', 'Weights' ]]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28756c-022d-4b65-a0ba-860d2dc6899a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pKa Calculation weighted avg\n",
    "if 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df['pka (acidic)'] = 0.7322 * (\n",
    "        E_avg_proton -\n",
    "        (result_df['Energy_original'] - result_df['Energy_deprotonated'])\n",
    "    )\n",
    "    pka_cal_acidic=sum(result_df['pka (acidic)']*result_df['Weights'])\n",
    "    \n",
    "if 'Energy_protonated' in result_df.columns:\n",
    "    result_df['pka (basic)'] = 0.7322 * ( E_avg_proton +(result_df['Energy_original'] - result_df['Energy_protonated']))\n",
    "    pka_cal_basic=sum(result_df['pka (basic)']*result_df['Weights'])\n",
    "\n",
    "result_df.to_csv(\"cluster_rep_conformers/conformerwise_pka.csv\",index=False)\n",
    "\n",
    "##print(\"pKa_calculated (weighted average) : \", pka_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c4a18-19f4-4238-bbb7-6fdf509467fb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Capture the end time\n",
    "end_time: float = time.time()\n",
    "\n",
    "# Calculate the execution time in seconds\n",
    "execution_time_seconds: float = end_time - start_time\n",
    "\n",
    "# Convert the execution time to minutes\n",
    "execution_time_minutes: int = execution_time_seconds // 60\n",
    "\n",
    "with open('outputs.txt', 'a') as file:\n",
    "    file.write(f'Execution_time : {execution_time_minutes}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72594f20-7a0f-483d-949e-dac9c3a77b96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Molecule\": [inp_smiles],\n",
    "    \"Solvent (ε)\": [dielectric_value],\n",
    "    \"# Conformers\": [len(result_df)],\n",
    "    \"pKa (Exp)\": [pKa_EXP],\n",
    "}\n",
    "\n",
    "try:\n",
    "    data[\"pKa_cal_acidic (weighted avg)\"] = [round(pka_cal_acidic, 1)]\n",
    "except NameError:\n",
    "    data[\"pKa_cal_acidic (weighted avg)\"] = [np.nan]\n",
    "try:\n",
    "    data[\"pKa_cal_basic (weighted avg)\"]= [round(pka_cal_basic, 1)]\n",
    "except NameError:\n",
    "    data[\"pKa_cal_basic (weighted avg)\"]= [np.nan]\n",
    "\n",
    "df_final = pd.DataFrame(data)\n",
    "df_final.to_csv(\"cluster_rep_conformers/Final_cal_pka.csv\",index=False)\n",
    "\n",
    "df_final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.023014,
   "end_time": "2025-07-17T10:29:42.829936",
   "environment_variables": {},
   "exception": true,
   "input_path": "full_pipeline_pka_rdkit_TD.ipynb",
   "output_path": "full_pipeline_pka_rdkit_TD_output.ipynb",
   "parameters": {
    "E_avg_proton": -275.755,
    "dielectric_value": 46.826,
    "inp_smiles": "NC(N)=O",
    "num_conf_rdkit": 200,
    "output_dir": "M2",
    "pKa_EXP": 24.88
   },
   "start_time": "2025-07-17T10:29:34.806922",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
