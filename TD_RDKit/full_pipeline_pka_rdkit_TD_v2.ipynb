{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08cd9069",
   "metadata": {
    "papermill": {
     "duration": 0.006312,
     "end_time": "2025-07-17T10:29:35.695835",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.689523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conformer Generation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971aa7f-5c76-4f35-9c81-4116d9657d34",
   "metadata": {
    "papermill": {
     "duration": 0.006373,
     "end_time": "2025-07-17T10:29:35.708596",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.702223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 1: Input Smile and Reference Conformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d501701-5206-48cd-b7da-e90f6caf7b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:35.722825Z",
     "iopub.status.busy": "2025-07-17T10:29:35.722355Z",
     "iopub.status.idle": "2025-07-17T10:29:35.725169Z",
     "shell.execute_reply": "2025-07-17T10:29:35.724678Z"
    },
    "papermill": {
     "duration": 0.01109,
     "end_time": "2025-07-17T10:29:35.725981",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.714891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Capture the start time\n",
    "start_time: float = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c7779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:35.739563Z",
     "iopub.status.busy": "2025-07-17T10:29:35.739144Z",
     "iopub.status.idle": "2025-07-17T10:29:35.741760Z",
     "shell.execute_reply": "2025-07-17T10:29:35.741305Z"
    },
    "papermill": {
     "duration": 0.01021,
     "end_time": "2025-07-17T10:29:35.742542",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.732332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add a folder to Python's import path\n",
    "sys.path.append('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a545a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:35.756111Z",
     "iopub.status.busy": "2025-07-17T10:29:35.755635Z",
     "iopub.status.idle": "2025-07-17T10:29:36.541910Z",
     "shell.execute_reply": "2025-07-17T10:29:36.541267Z"
    },
    "papermill": {
     "duration": 0.794602,
     "end_time": "2025-07-17T10:29:36.543489",
     "exception": false,
     "start_time": "2025-07-17T10:29:35.748887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from atk_conformer_generation_pipeline.utils import *\n",
    "from atk_conformer_generation_pipeline.variables import *\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df80ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:36.558431Z",
     "iopub.status.busy": "2025-07-17T10:29:36.557890Z",
     "iopub.status.idle": "2025-07-17T10:29:36.833913Z",
     "shell.execute_reply": "2025-07-17T10:29:36.833295Z"
    },
    "papermill": {
     "duration": 0.284335,
     "end_time": "2025-07-17T10:29:36.834937",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.550602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Change the dir to /work\n",
    "os.chdir(\"/work\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b42bf",
   "metadata": {
    "papermill": {
     "duration": 0.006441,
     "end_time": "2025-07-17T10:29:36.848279",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.841838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Change the below variables accordingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac382af3-999f-448f-b2aa-9dbc8156c0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:36.879229Z",
     "iopub.status.busy": "2025-07-17T10:29:36.878804Z",
     "iopub.status.idle": "2025-07-17T10:29:36.881685Z",
     "shell.execute_reply": "2025-07-17T10:29:36.881221Z"
    },
    "papermill": {
     "duration": 0.010598,
     "end_time": "2025-07-17T10:29:36.882510",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.871912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.chdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b3690-cdda-4863-8df0-a2d88dc4055b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:36.896209Z",
     "iopub.status.busy": "2025-07-17T10:29:36.895747Z",
     "iopub.status.idle": "2025-07-17T10:29:37.169761Z",
     "shell.execute_reply": "2025-07-17T10:29:37.169127Z"
    },
    "papermill": {
     "duration": 0.281823,
     "end_time": "2025-07-17T10:29:37.170713",
     "exception": false,
     "start_time": "2025-07-17T10:29:36.888890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba3694-7eed-4a2d-bc09-e0df8c6e5b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.185222Z",
     "iopub.status.busy": "2025-07-17T10:29:37.184688Z",
     "iopub.status.idle": "2025-07-17T10:29:37.187784Z",
     "shell.execute_reply": "2025-07-17T10:29:37.187313Z"
    },
    "papermill": {
     "duration": 0.011069,
     "end_time": "2025-07-17T10:29:37.188581",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.177512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "# set the maximum depth of the Python interpreter stack. This stack depth is crucial for recursive function calls, \n",
    "# as it limits how deep the recursion can go before causing a RecursionError."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439e673",
   "metadata": {
    "papermill": {
     "duration": 0.006304,
     "end_time": "2025-07-17T10:29:37.201302",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.194998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Importing the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61799b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.214983Z",
     "iopub.status.busy": "2025-07-17T10:29:37.214548Z",
     "iopub.status.idle": "2025-07-17T10:29:37.586264Z",
     "shell.execute_reply": "2025-07-17T10:29:37.585635Z"
    },
    "papermill": {
     "duration": 0.379989,
     "end_time": "2025-07-17T10:29:37.587665",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.207676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import csv\n",
    "from typing import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a5b54a-fca1-4027-a5a4-fef355b7d869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.602714Z",
     "iopub.status.busy": "2025-07-17T10:29:37.602101Z",
     "iopub.status.idle": "2025-07-17T10:29:37.606905Z",
     "shell.execute_reply": "2025-07-17T10:29:37.606402Z"
    },
    "papermill": {
     "duration": 0.01296,
     "end_time": "2025-07-17T10:29:37.607755",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.594795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Remove all files and directories created in the previous execution to avoid any confusion\n",
    "\n",
    "file_and_dir_to_remove: List[str]=[init_conf_xyz,opt_conf_SMILES_file,similarity_output_csv,\n",
    "feasible_geometries_csv,infeasible_geometries_csv,feasible_geometries_xyz,infeasible_geometries_xyz,pairwise_RMSDs_dat,\n",
    "pairwise_RMSDs_csv,cluster_reps_csv,cluster_reps_xyz,cluster_rep_prefix,cluster_reps_dir,clusters_RMSD_stats_csv,clusters_energy_stats_csv,\n",
    "opt_cluster_reps_csv]\n",
    "\n",
    "remove_paths(file_and_dir_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9339c7f",
   "metadata": {
    "papermill": {
     "duration": 0.006377,
     "end_time": "2025-07-17T10:29:37.620683",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.614306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2: Loading TD Conformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813266f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.667971Z",
     "iopub.status.busy": "2025-07-17T10:29:37.667379Z",
     "iopub.status.idle": "2025-07-17T10:29:37.685474Z",
     "shell.execute_reply": "2025-07-17T10:29:37.684925Z"
    },
    "papermill": {
     "duration": 0.026387,
     "end_time": "2025-07-17T10:29:37.686323",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.659936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf_file = \"conformers_TD.sdf\"\n",
    "\n",
    "# Load all conformers from the SDF file\n",
    "supplier = Chem.SDMolSupplier(sdf_file, removeHs=False)\n",
    "\n",
    "# Create a new molecule to hold all conformers\n",
    "mol_TD = None\n",
    "\n",
    "for i, m in enumerate(supplier):\n",
    "    if m is None:\n",
    "        print(f\"[Warning] Molecule {i} could not be read. Check formatting in SDF.\")\n",
    "        continue\n",
    "\n",
    "    if mol_TD is None:\n",
    "        mol_TD = Chem.Mol(m)\n",
    "        mol_TD.RemoveAllConformers()  # start with clean conformer list\n",
    "\n",
    "    # Add conformer with unique ID\n",
    "    conf = m.GetConformer()\n",
    "    conf.SetId(i)\n",
    "    mol_TD.AddConformer(conf, assignId=True)\n",
    "\n",
    "#save_conformers_to_sdf(mol_TD, \"conformers_TD.sdf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57361bc",
   "metadata": {
    "papermill": {
     "duration": 0.006501,
     "end_time": "2025-07-17T10:29:37.699498",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.692997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generating Conformers using RDKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0a75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.713702Z",
     "iopub.status.busy": "2025-07-17T10:29:37.713244Z",
     "iopub.status.idle": "2025-07-17T10:29:37.759815Z",
     "shell.execute_reply": "2025-07-17T10:29:37.759313Z"
    },
    "papermill": {
     "duration": 0.054642,
     "end_time": "2025-07-17T10:29:37.760736",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.706094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "mol_rdkit: Chem.Mol= generate_conformers(inp_smiles, num_conf_rdkit)  # Call the function to generate conformers\n",
    "save_conformers_to_sdf(mol_rdkit, \"conformers_RDKit.sdf\")       # Save conformers to SDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6eb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.775303Z",
     "iopub.status.busy": "2025-07-17T10:29:37.774786Z",
     "iopub.status.idle": "2025-07-17T10:29:37.829525Z",
     "shell.execute_reply": "2025-07-17T10:29:37.829052Z"
    },
    "papermill": {
     "duration": 0.062936,
     "end_time": "2025-07-17T10:29:37.830463",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.767527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_combine_conformers(mol1, mol2):\n",
    "    \"\"\"Simple conformer combination\"\"\"\n",
    "    \n",
    "    combined_mol = Chem.Mol(mol1)\n",
    "    combined_mol.RemoveAllConformers()\n",
    "    \n",
    "    # Add all conformers from both molecules\n",
    "    for i in range(mol1.GetNumConformers()):\n",
    "        conf = mol1.GetConformer(i)\n",
    "        combined_mol.AddConformer(conf, assignId=True)\n",
    "    \n",
    "    for i in range(mol2.GetNumConformers()):\n",
    "        conf = mol2.GetConformer(i)\n",
    "        combined_mol.AddConformer(conf, assignId=True)\n",
    "    \n",
    "    return combined_mol\n",
    "\n",
    "# Usage\n",
    "mol = simple_combine_conformers(mol_TD, mol_rdkit)\n",
    "save_conformers_to_sdf(mol, init_conf_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54476021-9587-4639-9c49-1e43794cbe7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.845616Z",
     "iopub.status.busy": "2025-07-17T10:29:37.844599Z",
     "iopub.status.idle": "2025-07-17T10:29:37.848239Z",
     "shell.execute_reply": "2025-07-17T10:29:37.847690Z"
    },
    "papermill": {
     "duration": 0.011809,
     "end_time": "2025-07-17T10:29:37.849070",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.837261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the number of atoms in the molecule\n",
    "num_atoms_generated_conf: int = mol.GetNumAtoms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06335009",
   "metadata": {
    "papermill": {
     "duration": 0.006687,
     "end_time": "2025-07-17T10:29:37.862630",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.855943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 3: Optimizing Conformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd3b5d-ebb2-457d-a450-4571df547b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:37.877388Z",
     "iopub.status.busy": "2025-07-17T10:29:37.876822Z",
     "iopub.status.idle": "2025-07-17T10:29:38.347475Z",
     "shell.execute_reply": "2025-07-17T10:29:38.346708Z"
    },
    "papermill": {
     "duration": 0.479221,
     "end_time": "2025-07-17T10:29:38.348595",
     "exception": false,
     "start_time": "2025-07-17T10:29:37.869374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### Optimize the generated conformers and save the optimized coordinates\n",
    "opt_mol, conformer_energies = mmff_optimize_conformers(mol)     # Call the function to optimize conformers\n",
    "save_conformers_to_sdf(opt_mol,opt_conf_sdf)\n",
    "#print(conformer_energies)\n",
    "\n",
    "num_opt_conf: int= opt_mol.GetNumConformers()\n",
    "\n",
    "### Save the energies of optimized to a CSV file\n",
    "conformer_energies_items : List[Tuple[int, float]] = list(conformer_energies.items())\n",
    "energy_DF: pd.DataFrame = pd.DataFrame(conformer_energies_items, columns=['conformer_id', 'energy_in_kcalpermol'])\n",
    "energy_DF.to_csv(opt_conf_energy_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ef898-74cc-4f15-9d93-f48eafa637d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:38.363990Z",
     "iopub.status.busy": "2025-07-17T10:29:38.363430Z",
     "iopub.status.idle": "2025-07-17T10:29:38.394719Z",
     "shell.execute_reply": "2025-07-17T10:29:38.394192Z"
    },
    "papermill": {
     "duration": 0.039721,
     "end_time": "2025-07-17T10:29:38.395587",
     "exception": false,
     "start_time": "2025-07-17T10:29:38.355866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Convert the 3D gometries of conformers into SMILES and save them\n",
    "convert_conformers_to_smiles(opt_conf_sdf,opt_conf_SMILES_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab01abc-5572-45e8-9822-e8ce5123fc3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:38.410135Z",
     "iopub.status.busy": "2025-07-17T10:29:38.409864Z",
     "iopub.status.idle": "2025-07-17T10:29:38.572856Z",
     "shell.execute_reply": "2025-07-17T10:29:38.572222Z"
    },
    "papermill": {
     "duration": 0.171575,
     "end_time": "2025-07-17T10:29:38.574093",
     "exception": false,
     "start_time": "2025-07-17T10:29:38.402518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Process optimized conformers to calculate Tanimoto similarity and separate feasible and infeasible geometries.\n",
    "infeasible_geom_DF, energy_DF=process_conformers(opt_conf_SMILES_file,opt_conf_sdf,feasible_geometries_sdf,infeasible_geometries_sdf,similarity_output_csv,infeasible_geometries_csv,inp_smiles,num_opt_conf,energy_DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c6c94-b01e-46fc-9593-9514ecd2abb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:38.589707Z",
     "iopub.status.busy": "2025-07-17T10:29:38.589154Z",
     "iopub.status.idle": "2025-07-17T10:29:38.593890Z",
     "shell.execute_reply": "2025-07-17T10:29:38.593367Z"
    },
    "papermill": {
     "duration": 0.013169,
     "end_time": "2025-07-17T10:29:38.594692",
     "exception": false,
     "start_time": "2025-07-17T10:29:38.581523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Calculate the numbers of conformers with feasible and infeasible geometries\n",
    "num_feasible_geom: int = len(energy_DF)\n",
    "num_infeasible_geom: int = len(infeasible_geom_DF)\n",
    "\n",
    "with open(\"outputs.txt\", 'a') as file:\n",
    "    file.write(f'Number_of_feasible_geometries: {num_feasible_geom}\\n')\n",
    "    \n",
    "print(\"Number of conformers with infeasible geometries:\", num_infeasible_geom)\n",
    "print(\"Number of conformers with feasible geometries:\", num_feasible_geom)\n",
    "print(\"Total number of conformers for which the geometry feasibility was checked:\", num_infeasible_geom+num_feasible_geom)\n",
    "#print(\"Total number of conformers generated:\", num_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d16929-3523-47c9-80b9-7e8c0da3ac0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:38.609415Z",
     "iopub.status.busy": "2025-07-17T10:29:38.608911Z",
     "iopub.status.idle": "2025-07-17T10:29:38.616850Z",
     "shell.execute_reply": "2025-07-17T10:29:38.616335Z"
    },
    "papermill": {
     "duration": 0.016078,
     "end_time": "2025-07-17T10:29:38.617698",
     "exception": false,
     "start_time": "2025-07-17T10:29:38.601620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Calculate the relative energies of conformers and write the results to a CSV file.\n",
    "rel_energy_DF: pd.DataFrame=calculate_relative_energies(energy_DF,feasible_geometries_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d6834-eaae-4a83-ab28-1012b547e916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:38.632440Z",
     "iopub.status.busy": "2025-07-17T10:29:38.631940Z",
     "iopub.status.idle": "2025-07-17T10:29:38.834167Z",
     "shell.execute_reply": "2025-07-17T10:29:38.833498Z"
    },
    "papermill": {
     "duration": 0.210539,
     "end_time": "2025-07-17T10:29:38.835134",
     "exception": false,
     "start_time": "2025-07-17T10:29:38.624595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "### Plot the relative energy distribution for conformers with feasible geometries\n",
    "n_bins=10\n",
    "plt.hist(rel_energy_DF['rel_energy_in_kcalpermol'], bins=n_bins, density=False, color='black', histtype='step', fill=False, lw=2)\n",
    "#density=False: If True, the histogram is normalized so that the area under the histogram integrates to 1. If False, the histogram represents the count of occurrences in each bin.\n",
    "#'bar': Traditional bar histogram (default)\n",
    "plt.xlabel('Rel. MMFF Energy (kcal/mol)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('MD')\n",
    "plt.grid(False)\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"rel_MMFF_energies-count_histogram\", bbox_inches='tight', pad_inches=0.04, transparent = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1fc8ae-38d5-49a4-8cae-a34775a7cbeb",
   "metadata": {
    "papermill": {
     "duration": 0.007215,
     "end_time": "2025-07-17T10:29:38.850097",
     "exception": false,
     "start_time": "2025-07-17T10:29:38.842882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 4: Calculating RMSD Matrix**\n",
    "\n",
    "Using Open Babel obrms command to calculate the Root Mean Square Deviation (RMSD) between the feasiable geometries present in an SDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e1781-89fe-471f-bb82-bb845f9b5f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:38.865652Z",
     "iopub.status.busy": "2025-07-17T10:29:38.865089Z",
     "iopub.status.idle": "2025-07-17T10:29:39.718921Z",
     "shell.execute_reply": "2025-07-17T10:29:39.718211Z"
    },
    "papermill": {
     "duration": 0.862847,
     "end_time": "2025-07-17T10:29:39.720132",
     "exception": false,
     "start_time": "2025-07-17T10:29:38.857285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Run obrms on the concatenated sdf file of conformers with feasible geometries to compute RMSD matrix\n",
    "calculate_rmsd(feasible_geometries_sdf,pairwise_RMSDs_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf060db-6d6c-4f87-b3ea-29ef96009664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:39.736472Z",
     "iopub.status.busy": "2025-07-17T10:29:39.736216Z",
     "iopub.status.idle": "2025-07-17T10:29:39.953520Z",
     "shell.execute_reply": "2025-07-17T10:29:39.952876Z"
    },
    "papermill": {
     "duration": 0.22674,
     "end_time": "2025-07-17T10:29:39.954722",
     "exception": false,
     "start_time": "2025-07-17T10:29:39.727982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from scipy.spatial.distance import squareform, is_valid_dm\n",
    "\n",
    "### Read the pairwise RMSD matrix from the output of obrms; it is supposed to be a hollow, asymmetric matrix\n",
    "rmsd_matrix_DF: pd.DataFrame = pd.read_csv(pairwise_RMSDs_dat, header=None, index_col=0)\n",
    "\n",
    "### Convert the pairwise RMSD matrix into a numpy float-type 2D array\n",
    "rmsd_matrix: np.ndarray = rmsd_matrix_DF.to_numpy(dtype=float)\n",
    "\n",
    "### Round the matrix elements to two decimal places to avoid possible asymmetry in the matrix due to insignificant numerical errors\n",
    "rmsd_matrix_2DP: np.ndarray  = np.round(rmsd_matrix, 2)\n",
    "\n",
    "# Force the matrix to be symmetric\n",
    "rmsd_matrix_2DP = (rmsd_matrix_2DP + rmsd_matrix_2DP.T) / 2\n",
    "\n",
    "# Check if the matrix is symmetric\n",
    "if not is_valid_dm(rmsd_matrix_2DP, throw=False):\n",
    "    raise ValueError(\"The provided RMSD matrix is not symmetric even after rounding and forcing symmetry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851cc88-7371-4439-b0c8-04ce6504eece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:39.972354Z",
     "iopub.status.busy": "2025-07-17T10:29:39.971704Z",
     "iopub.status.idle": "2025-07-17T10:29:40.031924Z",
     "shell.execute_reply": "2025-07-17T10:29:40.031287Z"
    },
    "papermill": {
     "duration": 0.070037,
     "end_time": "2025-07-17T10:29:40.033096",
     "exception": false,
     "start_time": "2025-07-17T10:29:39.963059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Convert the the pairwise distance matrix to its condensed form; write the pairwise RMSDs from the condensed matrix into a CSV file\n",
    "from scipy.spatial.distance import squareform\n",
    "condensed_matrix: np.ndarray  = squareform(rmsd_matrix_2DP)\n",
    "pairwise_RMSDs_DF: pd.DataFrame = pd.DataFrame(condensed_matrix)\n",
    "pairwise_RMSDs_DF.to_csv(pairwise_RMSDs_csv, header=['pairwise_RMSD'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85816e3-82a2-4bba-b80b-8cb6a53c4b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:40.050956Z",
     "iopub.status.busy": "2025-07-17T10:29:40.050233Z",
     "iopub.status.idle": "2025-07-17T10:29:40.354937Z",
     "shell.execute_reply": "2025-07-17T10:29:40.354300Z"
    },
    "papermill": {
     "duration": 0.314711,
     "end_time": "2025-07-17T10:29:40.356046",
     "exception": false,
     "start_time": "2025-07-17T10:29:40.041335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Plot the distribution of pairwise RMSDs\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "### Plot the histograms\n",
    "plt.hist(condensed_matrix, bins=8, density=True, color='black', fill=False, lw=2)\n",
    "\n",
    "### Format the axes\n",
    "plt.xlabel(r'RMSD ($\\AA)$')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Pairwise RMSDs')\n",
    "plt.grid(False)\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"pairwise_rmsd_distribution-PD.png\", bbox_inches='tight', pad_inches=0.04, transparent = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5227f49-febc-4c3b-a239-7159cd97fb55",
   "metadata": {
    "papermill": {
     "duration": 0.007652,
     "end_time": "2025-07-17T10:29:40.371998",
     "exception": false,
     "start_time": "2025-07-17T10:29:40.364346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 4: Hierarchical Cluster**\n",
    "\n",
    "Clustering the generated conformers into 20 clusters using hierarchical clustering with `ward` linkage method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3688fd-f0b5-43b1-8a3a-41e3ebec7969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:40.389131Z",
     "iopub.status.busy": "2025-07-17T10:29:40.388417Z",
     "iopub.status.idle": "2025-07-17T10:29:40.402334Z",
     "shell.execute_reply": "2025-07-17T10:29:40.401681Z"
    },
    "papermill": {
     "duration": 0.023493,
     "end_time": "2025-07-17T10:29:40.403279",
     "exception": false,
     "start_time": "2025-07-17T10:29:40.379786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Perform hierarchical clustering with 'ward' linkage method on the condensed version of pairwise distance matrix\n",
    "import scipy.cluster.hierarchy as sch\n",
    "linkage_matrix_ward: np.ndarray = sch.linkage(condensed_matrix, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9dc1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:40.421267Z",
     "iopub.status.busy": "2025-07-17T10:29:40.420446Z",
     "iopub.status.idle": "2025-07-17T10:29:40.588708Z",
     "shell.execute_reply": "2025-07-17T10:29:40.588061Z"
    },
    "papermill": {
     "duration": 0.178242,
     "end_time": "2025-07-17T10:29:40.589801",
     "exception": false,
     "start_time": "2025-07-17T10:29:40.411559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### A few settings to export the image of the plot\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "### Plot the dendrogram to visualize the hierarchical clustering structure\n",
    "sch.dendrogram(linkage_matrix_ward, no_labels=True)\n",
    "plt.title('Dendrogram with Ward Linkage Method')\n",
    "plt.xlabel('Conformers')\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"hierarchical_clustering_dendogram-ward.png\", bbox_inches='tight', pad_inches=0.04, transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f04fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:40.608098Z",
     "iopub.status.busy": "2025-07-17T10:29:40.607525Z",
     "iopub.status.idle": "2025-07-17T10:29:41.536307Z",
     "shell.execute_reply": "2025-07-17T10:29:41.535578Z"
    },
    "papermill": {
     "duration": 0.938823,
     "end_time": "2025-07-17T10:29:41.537331",
     "exception": false,
     "start_time": "2025-07-17T10:29:40.598508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### A few settings to export the image of the plot\n",
    "# plt.style.use('~/matplotlib_templates/single_column.mplstyle')\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "### Determine the optimal number of clusters using silhouette score; the original pairwise RMSD matrix must be used for this\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "## Calculate silhouette score for different numbers of clusters\n",
    "sil_scores = []\n",
    "range_n_clusters = list(range(2, 101))     # Try different numbers of clusters\n",
    "for n_clusters in range_n_clusters:\n",
    "    cluster_labels = fcluster(linkage_matrix_ward, n_clusters, criterion='maxclust')\n",
    "    cluster_counts = Counter(cluster_labels)\n",
    "    # print(cluster_counts)\n",
    "    \n",
    "    # Check if the clustering resulted in more than one cluster\n",
    "    if len(cluster_counts) > 1:\n",
    "        sil_score = silhouette_score(rmsd_matrix_2DP, cluster_labels, metric='precomputed')\n",
    "        sil_scores.append(sil_score)\n",
    "    else:\n",
    "        sil_scores.append(float('-inf'))  # Append a very low score if there's only one cluster    \n",
    "\n",
    "\n",
    "## Plot the Silhouette scores\n",
    "plt.plot(range_n_clusters, sil_scores, marker='o', color='black', fillstyle='none', ms=2, lw=2)\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Ward Linkage\")\n",
    "plt.axis([-5, 105, -0.05, 1.05])\n",
    "plt.xticks([0, 25, 50, 75, 100])\n",
    "plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"silhouette_score_vs_num_clust-ward.png\", bbox_inches='tight', pad_inches=0.04, transparent = False)\n",
    "\n",
    "## Find the optimal number of clusters based on the maximum value of silhouette score and printing it\n",
    "max_sil_score = np.max(sil_scores)\n",
    "optimal_clusters = range_n_clusters[np.argmax(sil_scores)]\n",
    "print(f\"The optimal number of clusters is {optimal_clusters} with a silhouette score of {max_sil_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae62551-a2a0-4c22-87c3-134bbf204b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:41.555996Z",
     "iopub.status.busy": "2025-07-17T10:29:41.555415Z",
     "iopub.status.idle": "2025-07-17T10:29:41.562013Z",
     "shell.execute_reply": "2025-07-17T10:29:41.561473Z"
    },
    "papermill": {
     "duration": 0.016636,
     "end_time": "2025-07-17T10:29:41.562887",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.546251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "num_clusters = 5 if optimal_clusters > 5 else optimal_clusters\n",
    "\n",
    "## For each conformer, assign the cluster label to which it belongs\n",
    "cluster_labels: np.ndarray = fcluster(linkage_matrix_ward, num_clusters, criterion='maxclust')\n",
    "\n",
    "## Create an empty dictionary to store the cluster sets\n",
    "clusters: Dict[int, List[int]] = {i: [] for i in range(1, num_clusters + 1)}\n",
    "\n",
    "## Assign each cluster label to the respective cluster set\n",
    "for index, label in enumerate(cluster_labels):\n",
    "    clusters[label].append(index)     # Store the indices instead of raw data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16848016-bf7b-433e-be19-52d32e64231a",
   "metadata": {
    "papermill": {
     "duration": 0.008229,
     "end_time": "2025-07-17T10:29:41.579576",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.571347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 5: Identifying Cluster Representative**\n",
    "\n",
    "Identifying the minimum energy conformer within each cluster as its representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38530063-2a90-4be7-a1f3-37adf6831120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:41.597270Z",
     "iopub.status.busy": "2025-07-17T10:29:41.596814Z",
     "iopub.status.idle": "2025-07-17T10:29:41.608760Z",
     "shell.execute_reply": "2025-07-17T10:29:41.608247Z"
    },
    "papermill": {
     "duration": 0.021709,
     "end_time": "2025-07-17T10:29:41.609623",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.587914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Identify the minimum energy conformer within each cluster as its representative\n",
    "\n",
    "## Loop over all the cluster sets\n",
    "cluster_reps_list: List[pd.DataFrame] = []\n",
    "\n",
    "for clust_label, clust_elements in clusters.items():\n",
    "    if len(clust_elements)!=0:\n",
    "        clust_DF: pd.DataFrame = rel_energy_DF.loc[clust_elements]     # Extract the relative energies of the cluster elements into a dataframe\n",
    "        min_energy_index: int = clust_DF['rel_energy_in_kcalpermol'].idxmin()     # Find the row index correspoding to the minimum relative energy conformer within the cluster \n",
    "        min_energy_DF: pd.DataFrame= clust_DF.loc[[min_energy_index]]     # Isolate the repesentative conformer's relative energy into a dataframe\n",
    "        min_energy_DF['cluster_id'] = clust_label     # Add the 'cluster ID' information to the above dataframe\n",
    "        # print(min_energy_DF)\n",
    "        cluster_reps_list.append(min_energy_DF)     # Append the dataframe corresponding to each cluster representative into a list of dataframes\n",
    "\n",
    "## Concatenate the dataframes of all cluster representatives into a single dataframe\n",
    "cluster_reps_DF: pd.DataFrame = pd.concat(cluster_reps_list, ignore_index=True)\n",
    "\n",
    "## Sort the cluster respresentatives samples by 'conformer_id' and save the sorted dataframe to a csv file\n",
    "sorted_cluster_reps_DF: pd.DataFrame = cluster_reps_DF.sort_values(by='conformer_id', ascending=True)\n",
    "sorted_cluster_reps_DF.to_csv(cluster_reps_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89aa89-9c42-4721-99a7-10b0504d2774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:41.627634Z",
     "iopub.status.busy": "2025-07-17T10:29:41.627183Z",
     "iopub.status.idle": "2025-07-17T10:29:41.665273Z",
     "shell.execute_reply": "2025-07-17T10:29:41.664592Z"
    },
    "papermill": {
     "duration": 0.048213,
     "end_time": "2025-07-17T10:29:41.666307",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.618094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "###  Write the coordinates of cluster representative conformers to SDF files.\n",
    "write_cluster_representatives(opt_conf_sdf,cluster_reps_dir,cluster_reps_sdf,sorted_cluster_reps_DF,cluster_reps_DF,cluster_rep_prefix,conf_extension)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6978d0c",
   "metadata": {
    "papermill": {
     "duration": 0.008453,
     "end_time": "2025-07-17T10:29:41.683806",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.675353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 7: Geometry optimization of neutral conformers using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752a24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:41.701913Z",
     "iopub.status.busy": "2025-07-17T10:29:41.701335Z",
     "iopub.status.idle": "2025-07-17T10:29:41.995351Z",
     "shell.execute_reply": "2025-07-17T10:29:41.994561Z"
    },
    "papermill": {
     "duration": 0.304667,
     "end_time": "2025-07-17T10:29:41.996886",
     "exception": false,
     "start_time": "2025-07-17T10:29:41.692219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python /app/dft_main.py DFT {cluster_reps_dir} {dielectric_value} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7d5b9-6e34-42e0-866b-1135a2938ceb",
   "metadata": {
    "papermill": {
     "duration": 0.008539,
     "end_time": "2025-07-17T10:29:42.014722",
     "exception": false,
     "start_time": "2025-07-17T10:29:42.006183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 9: Geometry optimization of charged conformers using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e532a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:29:42.058769Z",
     "iopub.status.busy": "2025-07-17T10:29:42.058304Z",
     "iopub.status.idle": "2025-07-17T10:29:42.303379Z",
     "shell.execute_reply": "2025-07-17T10:29:42.302551Z"
    },
    "papermill": {
     "duration": 0.255024,
     "end_time": "2025-07-17T10:29:42.304247",
     "exception": true,
     "start_time": "2025-07-17T10:29:42.049223",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basis and XC\n",
    "basis_sets = ['aug-cc-pVDZ']\n",
    "xc_functionals = ['M06-2X']  # Add more if needed\n",
    "\n",
    "for basis in basis_sets:\n",
    "        for xc in xc_functionals:\n",
    "             # Sanitize names for filename safety\n",
    "            basis_tag = basis.replace(\"(\", \"\").replace(\")\", \"\").replace(\"*\", \"\").replace(\"+\", \"\").replace(\"/\", \"-\").replace(\" \", \"\")\n",
    "            xc_tag = xc.replace(\"(\", \"\").replace(\")\", \"\").replace(\"*\", \"\").replace(\"+\", \"\").replace(\"/\", \"-\").replace(\" \", \"\")\n",
    "\n",
    "# Get list of SDF files\n",
    "sdf_files = sorted(glob.glob(os.path.join(cluster_reps_dir, \"*.sdf\")))\n",
    "\n",
    "# Loop over each SDF file\n",
    "for sdf_path in sdf_files:\n",
    "    sdf_filename = os.path.basename(sdf_path)\n",
    "    sdf_stem = os.path.splitext(sdf_filename)[0]  # Remove .sdf extension\n",
    "\n",
    "    for basis in basis_sets:\n",
    "        for xc in xc_functionals:\n",
    "            \n",
    "            # Output file names\n",
    "            new_filename = f\"{sdf_stem}_{basis_tag}_{xc_tag}.sdf\"\n",
    "            new_filepath = os.path.join(cluster_reps_dir, new_filename)\n",
    "            shutil.copy(sdf_path, new_filepath)\n",
    "            print(\"Renamed output will be:\", new_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df22ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T18:47:51.833034Z",
     "iopub.status.busy": "2025-05-22T18:47:51.832369Z",
     "iopub.status.idle": "2025-05-22T18:47:52.174441Z",
     "shell.execute_reply": "2025-05-22T18:47:52.173730Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define base paths\n",
    "base_dir = f\"/work/{output_dir}/cluster_rep_conformers\"\n",
    "treated_dir = os.path.join(base_dir, \"treated\")\n",
    "\n",
    "# Run the external Python script\n",
    "subprocess.run([\n",
    "    \"python\",\n",
    "    \"/app/ionization_tool_with_ranking/main.py\",\n",
    "    base_dir\n",
    "], check=True)\n",
    "\n",
    "# Move all .sdf files from treated/ to base_dir\n",
    "sdf_files = glob.glob(os.path.join(treated_dir, \"*.sdf\"))\n",
    "for file_path in sdf_files:\n",
    "    shutil.move(file_path, base_dir)\n",
    "\n",
    "# Remove the treated directory\n",
    "shutil.rmtree(treated_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abca850",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /app/dft_main.py DFT_DEPROTO {cluster_reps_dir} {dielectric_value} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa20541-9f07-495a-82ec-352a68c06a68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Step 10: Accumulating DFT data and Writing the CSV for pKa Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6634319",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe_from_xyz_files(folder_path):\n",
    "    \"\"\"\n",
    "    Creates a pandas DataFrame from .xyz files in a given folder,\n",
    "    extracting Basis, XC, and energy.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the .xyz files.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with 'file name', 'Basis', 'XC', and 'energy' columns.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Updated Regex to match the filename pattern and capture Basis and XC\n",
    "    # This regex is more robust to handle basis sets and XC functionals\n",
    "    # that may contain hyphens, numbers, or specific characters.\n",
    "    # It assumes the structure is:\n",
    "    # rep_of_cluster_N_BASIS_XC_optional_treatment.xyz\n",
    "    filename_pattern = re.compile(\n",
    "        r\"rep_of_cluster_\\d+_([a-zA-Z0-9\\-]+)_([a-zA-Z0-9\\-]+)(?:_deprotonated|_protonated)?\\.xyz\"\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".xyz\"):\n",
    "            match = filename_pattern.match(filename)\n",
    "            if match:\n",
    "                basis = match.group(1)\n",
    "                xc = match.group(2)\n",
    "\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        f.readline()  # Skip the first line (number of atoms)\n",
    "                        energy_line = f.readline().strip()\n",
    "\n",
    "                        energy = None\n",
    "                        try:\n",
    "                            energy = float(energy_line)\n",
    "                        except ValueError:\n",
    "                            energy_match = re.search(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", energy_line)\n",
    "                            if energy_match:\n",
    "                                energy = float(energy_match.group(0))\n",
    "                            else:\n",
    "                                print(f\"Could not extract energy from line: '{energy_line}' in file: {filename}\")\n",
    "\n",
    "                        data.append({\n",
    "                            'file name': filename,\n",
    "                            'Basis': basis,\n",
    "                            'XC': xc,\n",
    "                            'energy': energy\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"Filename pattern did not match for: {filename}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# --- How to use the function ---\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_dataframe_from_xyz_files(cluster_reps_dir)\n",
    "\n",
    "\n",
    "df.head(15)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cb9ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---\n",
    "# Step 1: Extract the Common Prefix\n",
    "def extract_prefix(filename):\n",
    "    match = re.match(r'(rep_of_cluster_\\d+_aug-cc-pVDZ_M06-2X)', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return filename\n",
    "\n",
    "df['prefix'] = df['file name'].apply(extract_prefix)\n",
    "\n",
    "# ---\n",
    "# Step 2: Group and Process to Assign Custom Names, including Basis and XC\n",
    "\n",
    "output_rows = []\n",
    "for prefix, group in df.groupby('prefix'):\n",
    "    row_dict = {'Prefix': prefix}\n",
    "    \n",
    "    # Get Basis and XC from the first row of the group (they should be constant within the group)\n",
    "    # Using .iloc[0] is safe here because each group will have at least one row\n",
    "    row_dict['Basis'] = group['Basis'].iloc[0]\n",
    "    row_dict['XC'] = group['XC'].iloc[0]\n",
    "\n",
    "    # Initialize placeholders for the new columns\n",
    "    row_dict['Filename_original'] = None\n",
    "    row_dict['Energy_original'] = None\n",
    "    row_dict['Filename_acid_treated'] = None\n",
    "    row_dict['Energy_acid_treated'] = None\n",
    "    row_dict['Filename_base_treated'] = None\n",
    "    row_dict['Energy_base_treated'] = None\n",
    "\n",
    "\n",
    "    for _, entry in group.iterrows():\n",
    "        filename = entry['file name']\n",
    "        energy = entry['energy']\n",
    "\n",
    "        if '_deprotonated' in filename:\n",
    "            row_dict['Filename_deprotonated'] = filename\n",
    "            row_dict['Energy_deprotonated'] = energy\n",
    "        elif '_protonated' in filename:\n",
    "            row_dict['Filename_protonated'] = filename\n",
    "            row_dict['Energy_protonated'] = energy\n",
    "        else:\n",
    "            # Assuming files without _acid_treat or _base_treat are the 'original'\n",
    "            row_dict['Filename_original'] = filename\n",
    "            row_dict['Energy_original'] = energy\n",
    "            \n",
    "    output_rows.append(row_dict)\n",
    "\n",
    "result_df = pd.DataFrame(output_rows)\n",
    "\n",
    "# Reorder columns for better readability\n",
    "# Ensure all these columns exist in result_df before attempting to reorder\n",
    "desired_columns = ['Prefix', 'Basis', 'XC',\n",
    "                   'Filename_original', 'Energy_original',\n",
    "                   'Filename_deprotonated', 'Energy_deprotonated',\n",
    "                   'Filename_protonated', 'Energy_protonated']\n",
    "\n",
    "# Filter for only the columns that actually exist in result_df to avoid errors\n",
    "existing_columns = [col for col in desired_columns if col in result_df.columns]\n",
    "result_df = result_df[existing_columns]\n",
    "\n",
    "\n",
    "#print\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02983554-0efb-4ad7-afba-4d8755aac0d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Step 11: Data analysis and pKa Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e7287-08f9-4e46-9d38-587dd275e0ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df['E_proton (acidic)']=pKa_EXP*1.36574 +(result_df['Energy_original'] -result_df['Energy_deprotonated'])\n",
    "if 'Energy_protonated' in result_df.columns:\n",
    "    result_df['E_proton (basic)']=pKa_EXP*1.36574 -(result_df['Energy_original'] -result_df['Energy_protonated'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734caa6-deb6-45d4-835e-874293e3fb28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = 298  # Temperature in Kelvin\n",
    "k_B = 0.0019872041  # Boltzmann constant in kcal/mol·K\n",
    "\n",
    "E_shifted = result_df['Energy_original'] - result_df['Energy_original'].min()  # shift energies so lowest is 0\n",
    "weights = np.exp(-E_shifted / (k_B * T))\n",
    "\n",
    "#Boltzmann Probabilities\n",
    "result_df['Weights'] = weights / np.sum(weights)\n",
    "\n",
    "if 'Energy_deprotonated' in result_df.columns and 'Energy_protonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original', 'Energy_deprotonated','E_proton (acidic)','Energy_protonated', 'E_proton (basic)', 'Weights' ]]\n",
    "\n",
    "elif 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original', 'Energy_deprotonated','E_proton (acidic)','Weights' ]]\n",
    "\n",
    "elif 'Energy_protonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original','Energy_protonated', 'E_proton (basic)', 'Weights' ]]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28756c-022d-4b65-a0ba-860d2dc6899a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pKa Calculation weighted avg\n",
    "if 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df['pka (acidic)'] = 0.7322 * (\n",
    "        E_avg_proton -\n",
    "        (result_df['Energy_original'] - result_df['Energy_deprotonated'])\n",
    "    )\n",
    "    pka_cal_acidic=sum(result_df['pka (acidic)']*result_df['Weights'])\n",
    "    \n",
    "if 'Energy_protonated' in result_df.columns:\n",
    "    result_df['pka (basic)'] = 0.7322 * ( E_avg_proton +(result_df['Energy_original'] - result_df['Energy_protonated']))\n",
    "    pka_cal_basic=sum(result_df['pka (basic)']*result_df['Weights'])\n",
    "\n",
    "result_df.to_csv(\"cluster_rep_conformers/conformerwise_pka.csv\",index=False)\n",
    "\n",
    "##print(\"pKa_calculated (weighted average) : \", pka_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c4a18-19f4-4238-bbb7-6fdf509467fb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Capture the end time\n",
    "end_time: float = time.time()\n",
    "\n",
    "# Calculate the execution time in seconds\n",
    "execution_time_seconds: float = end_time - start_time\n",
    "\n",
    "# Convert the execution time to minutes\n",
    "execution_time_minutes: int = execution_time_seconds // 60\n",
    "\n",
    "with open('outputs.txt', 'a') as file:\n",
    "    file.write(f'Execution_time : {execution_time_minutes}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72594f20-7a0f-483d-949e-dac9c3a77b96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Molecule\": [inp_smiles],\n",
    "    \"Solvent (ε)\": [dielectric_value],\n",
    "    \"# Conformers\": [len(cluster_reps_DF)],\n",
    "    \"pKa (Exp)\": [pKa_EXP],\n",
    "}\n",
    "\n",
    "try:\n",
    "    data[\"pKa_cal_acidic (weighted avg)\"] = [round(pka_cal_acidic, 1)]\n",
    "except NameError:\n",
    "    data[\"pKa_cal_acidic (weighted avg)\"] = [np.nan]\n",
    "try:\n",
    "    data[\"pKa_cal_basic (weighted avg)\"]= [round(pka_cal_basic, 1)]\n",
    "except NameError:\n",
    "    data[\"pKa_cal_basic (weighted avg)\"]= [np.nan]\n",
    "\n",
    "df_final = pd.DataFrame(data)\n",
    "df_final.to_csv(\"cluster_rep_conformers/Final_cal_pka.csv\",index=False)\n",
    "\n",
    "df_final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.023014,
   "end_time": "2025-07-17T10:29:42.829936",
   "environment_variables": {},
   "exception": true,
   "input_path": "full_pipeline_pka_rdkit_TD.ipynb",
   "output_path": "full_pipeline_pka_rdkit_TD_output.ipynb",
   "parameters": {
    "E_avg_proton": -275.755,
    "dielectric_value": 46.826,
    "inp_smiles": "NC(N)=O",
    "num_conf_rdkit": 200,
    "output_dir": "M2",
    "pKa_EXP": 24.88
   },
   "start_time": "2025-07-17T10:29:34.806922",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
