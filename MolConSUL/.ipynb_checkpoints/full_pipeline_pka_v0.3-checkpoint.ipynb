{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08cd9069",
   "metadata": {
    "papermill": {
     "duration": 0.007362,
     "end_time": "2025-05-22T18:14:30.261283",
     "exception": false,
     "start_time": "2025-05-22T18:14:30.253921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conformer Generation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971aa7f-5c76-4f35-9c81-4116d9657d34",
   "metadata": {
    "papermill": {
     "duration": 0.005888,
     "end_time": "2025-05-22T18:14:30.273596",
     "exception": false,
     "start_time": "2025-05-22T18:14:30.267708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 1: Input Smile and Reference Conformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d501701-5206-48cd-b7da-e90f6caf7b03",
   "metadata": {
    "papermill": {
     "duration": 0.015388,
     "end_time": "2025-05-22T18:14:30.294800",
     "exception": false,
     "start_time": "2025-05-22T18:14:30.279412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Capture the start time\n",
    "start_time: float = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989c7779",
   "metadata": {
    "papermill": {
     "duration": 0.009856,
     "end_time": "2025-05-22T18:14:30.311131",
     "exception": false,
     "start_time": "2025-05-22T18:14:30.301275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add a folder to Python's import path\n",
    "sys.path.append('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65de8e15",
   "metadata": {
    "papermill": {
     "duration": 1.479011,
     "end_time": "2025-05-22T18:14:31.796003",
     "exception": false,
     "start_time": "2025-05-22T18:14:30.316992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from atk_conformer_generation_pipeline.utils import *\n",
    "from atk_conformer_generation_pipeline.variables import *\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "from pyscf import gto\n",
    "from pyscf.geomopt import geometric_solver\n",
    "from gpu4pyscf.dft import rks\n",
    "from pyscf.hessian import thermo\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93df80ed",
   "metadata": {
    "papermill": {
     "duration": 0.310772,
     "end_time": "2025-05-22T18:14:32.113334",
     "exception": false,
     "start_time": "2025-05-22T18:14:31.802562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "#Change the dir to /work\n",
    "os.chdir(\"/app\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b42bf",
   "metadata": {
    "papermill": {
     "duration": 0.006195,
     "end_time": "2025-05-22T18:14:32.126088",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.119893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Change the below variables accordingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefcb4f6-adfe-4aba-bff3-f6d5701ca04a",
   "metadata": {
    "papermill": {
     "duration": 0.012271,
     "end_time": "2025-05-22T18:14:32.144407",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.132136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_smiles: str=\"NC(=O)CO\"\n",
    "dielectric_value: float=46.826\n",
    "output_dir: str=\"shifath_test\"\n",
    "num_conf_rdkit: int = 1000     # Number of conformers to be generated\n",
    "E_avg_proton: float=-277.60  # E_H (solv) in kcal/mol\n",
    "pKa_EXP: float=23.00 # Experimental pKa\n",
    "\n",
    "# inp_smiles: str = \"CCO\"                     # Ethanol\n",
    "# dielectric_value: float = 78.355            # Dielectric constant for water\n",
    "# output_dir: str = \"ethanol_test_2\"            # New output folder\n",
    "# num_conf_rdkit: int = 500                   # Fewer conformers needed for simple molecule\n",
    "# E_avg_proton: float = -270.28               # kcal/mol, estimated E_H(solv) for water\n",
    "# pKa_EXP: float = 15.9                       # Experimental pKa of ethanol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac382af3-999f-448f-b2aa-9dbc8156c0e2",
   "metadata": {
    "papermill": {
     "duration": 0.010673,
     "end_time": "2025-05-22T18:14:32.161073",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.150400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.chdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61b3690-cdda-4863-8df0-a2d88dc4055b",
   "metadata": {
    "papermill": {
     "duration": 0.310189,
     "end_time": "2025-05-22T18:14:32.477238",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.167049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/shifath_test\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ba3694-7eed-4a2d-bc09-e0df8c6e5b6b",
   "metadata": {
    "papermill": {
     "duration": 0.011488,
     "end_time": "2025-05-22T18:14:32.495371",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.483883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "# set the maximum depth of the Python interpreter stack. This stack depth is crucial for recursive function calls, \n",
    "# as it limits how deep the recursion can go before causing a RecursionError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a4ad092-ac6d-4f1f-b825-a9beead92c6e",
   "metadata": {
    "papermill": {
     "duration": 0.030657,
     "end_time": "2025-05-22T18:14:32.532093",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.501436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_2d_structure(inp_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439e673",
   "metadata": {
    "papermill": {
     "duration": 0.006239,
     "end_time": "2025-05-22T18:14:32.544635",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.538396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Importing the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61799b39",
   "metadata": {
    "papermill": {
     "duration": 0.348934,
     "end_time": "2025-05-22T18:14:32.899817",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.550883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import csv\n",
    "from typing import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a5b54a-fca1-4027-a5a4-fef355b7d869",
   "metadata": {
    "papermill": {
     "duration": 0.017255,
     "end_time": "2025-05-22T18:14:32.923981",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.906726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path initial_generated_conformers.sdf does not exist.\n",
      "The path optimized_generated_conformers.sdf does not exist.\n",
      "The path opt_conf_energies.csv does not exist.\n",
      "The path optimized_generated_conformers.smi does not exist.\n",
      "The path tanimoto_similarity.csv does not exist.\n",
      "The path feasible_geom_energies.csv does not exist.\n",
      "The path infeasible_geometries.csv does not exist.\n",
      "The path feasible_geometries.xyz does not exist.\n",
      "The path infeasible_geometries.xyz does not exist.\n",
      "The path rmsd_matrix-mx_flags.dat does not exist.\n",
      "The path pairwise_RMSDs.csv does not exist.\n",
      "The path cluster_rep_conformers.csv does not exist.\n",
      "The path cluster_rep_conformers.xyz does not exist.\n",
      "The path rep_of_cluster_ does not exist.\n",
      "The path cluster_rep_conformers does not exist.\n",
      "The path cluster_statistics-RMSDs.csv does not exist.\n",
      "The path cluster_statistics-energies.csv does not exist.\n",
      "The path opt_cluster_rep_conformers.csv does not exist.\n",
      "CPU times: user 505 µs, sys: 0 ns, total: 505 µs\n",
      "Wall time: 344 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Remove all files and directories created in the previous execution to avoid any confusion\n",
    "\n",
    "file_and_dir_to_remove: List[str]=[init_conf_xyz,opt_conf_xyz,opt_conf_energy_csv,opt_conf_SMILES_file,similarity_output_csv,\n",
    "feasible_geometries_csv,infeasible_geometries_csv,feasible_geometries_xyz,infeasible_geometries_xyz,pairwise_RMSDs_dat,\n",
    "pairwise_RMSDs_csv,cluster_reps_csv,cluster_reps_xyz,cluster_rep_prefix,cluster_reps_dir,clusters_RMSD_stats_csv,clusters_energy_stats_csv,\n",
    "opt_cluster_reps_csv]\n",
    "\n",
    "remove_paths(file_and_dir_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8dc60-c6f9-4eb3-9f8c-eb9edd5f7b0c",
   "metadata": {
    "papermill": {
     "duration": 0.034716,
     "end_time": "2025-05-22T18:14:32.965196",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.930480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 2: Generating Conformers**\n",
    "\n",
    "Generating conformers for a given molecule using the RDKit-ETKDG method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3e58d9-a3a0-4bfe-8e95-a579ab4ead46",
   "metadata": {
    "papermill": {
     "duration": 2.819278,
     "end_time": "2025-05-22T18:14:35.791010",
     "exception": false,
     "start_time": "2025-05-22T18:14:32.971732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_conf_rdkit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_conf_rdkit' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "mol: Chem.Mol= generate_conformers(inp_smiles, num_conf_rdkit)  # Call the function to generate conformers\n",
    "save_conformers_to_sdf(mol, init_conf_sdf)       # Save conformers to SDF file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54476021-9587-4639-9c49-1e43794cbe7c",
   "metadata": {
    "papermill": {
     "duration": 0.011366,
     "end_time": "2025-05-22T18:14:35.809695",
     "exception": false,
     "start_time": "2025-05-22T18:14:35.798329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the number of atoms in the molecule\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m num_atoms_generated_conf: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmol\u001b[49m\u001b[38;5;241m.\u001b[39mGetNumAtoms()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mol' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the number of atoms in the molecule\n",
    "num_atoms_generated_conf: int = mol.GetNumAtoms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784495fe-73bb-4073-bbee-5bb5ad533e61",
   "metadata": {
    "papermill": {
     "duration": 0.006468,
     "end_time": "2025-05-22T18:14:35.822701",
     "exception": false,
     "start_time": "2025-05-22T18:14:35.816233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 3: Optimizing Conformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd3b5d-ebb2-457d-a450-4571df547b17",
   "metadata": {
    "papermill": {
     "duration": 21.384203,
     "end_time": "2025-05-22T18:14:57.213415",
     "exception": false,
     "start_time": "2025-05-22T18:14:35.829212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Optimize the generated conformers and save the optimized coordinates\n",
    "opt_mol, conformer_energies = mmff_optimize_conformers(mol)     # Call the function to optimize conformers\n",
    "save_conformers_to_sdf(opt_mol,opt_conf_sdf)\n",
    "# print(conformer_energies)\n",
    "\n",
    "num_opt_conf: int= opt_mol.GetNumConformers()\n",
    "\n",
    "\n",
    "### Save the energies of optimized to a CSV file\n",
    "conformer_energies_items : List[Tuple[int, float]] = list(conformer_energies.items())\n",
    "energy_DF: pd.DataFrame = pd.DataFrame(conformer_energies_items, columns=['conformer_id', 'energy_in_kcalpermol'])\n",
    "energy_DF.to_csv(opt_conf_energy_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ef898-74cc-4f15-9d93-f48eafa637d2",
   "metadata": {
    "papermill": {
     "duration": 0.372369,
     "end_time": "2025-05-22T18:14:57.593442",
     "exception": false,
     "start_time": "2025-05-22T18:14:57.221073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Convert the 3D gometries of conformers into SMILES and save them\n",
    "convert_conformers_to_smiles(opt_conf_sdf,opt_conf_SMILES_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab01abc-5572-45e8-9822-e8ce5123fc3c",
   "metadata": {
    "papermill": {
     "duration": 1.06011,
     "end_time": "2025-05-22T18:14:58.660990",
     "exception": false,
     "start_time": "2025-05-22T18:14:57.600880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Process optimized conformers to calculate Tanimoto similarity and separate feasible and infeasible geometries.\n",
    "infeasible_geom_DF, energy_DF=process_conformers(opt_conf_SMILES_file,opt_conf_sdf,feasible_geometries_sdf,infeasible_geometries_sdf,similarity_output_csv,infeasible_geometries_csv,inp_smiles,num_opt_conf,energy_DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c6c94-b01e-46fc-9593-9514ecd2abb4",
   "metadata": {
    "papermill": {
     "duration": 0.013759,
     "end_time": "2025-05-22T18:14:58.682399",
     "exception": false,
     "start_time": "2025-05-22T18:14:58.668640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Calculate the numbers of conformers with feasible and infeasible geometries\n",
    "num_feasible_geom: int = len(energy_DF)\n",
    "num_infeasible_geom: int = len(infeasible_geom_DF)\n",
    "\n",
    "with open(\"outputs.txt\", 'a') as file:\n",
    "    file.write(f'Number_of_feasible_geometries: {num_feasible_geom}\\n')\n",
    "    \n",
    "print(\"Number of conformers with infeasible geometries:\", num_infeasible_geom)\n",
    "print(\"Number of conformers with feasible geometries:\", num_feasible_geom)\n",
    "print(\"Total number of conformers for which the geometry feasibility was checked:\", num_infeasible_geom+num_feasible_geom)\n",
    "print(\"Total number of conformers generated:\", num_conf_rdkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d16929-3523-47c9-80b9-7e8c0da3ac0d",
   "metadata": {
    "papermill": {
     "duration": 0.018682,
     "end_time": "2025-05-22T18:14:58.707940",
     "exception": false,
     "start_time": "2025-05-22T18:14:58.689258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Calculate the relative energies of conformers and write the results to a CSV file.\n",
    "rel_energy_DF: pd.DataFrame=calculate_relative_energies(energy_DF,feasible_geometries_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d6834-eaae-4a83-ab28-1012b547e916",
   "metadata": {
    "papermill": {
     "duration": 0.176777,
     "end_time": "2025-05-22T18:14:58.891629",
     "exception": false,
     "start_time": "2025-05-22T18:14:58.714852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "### Plot the relative energy distribution for conformers with feasible geometries\n",
    "n_bins=10\n",
    "plt.hist(rel_energy_DF['rel_energy_in_kcalpermol'], bins=n_bins, density=False, color='black', histtype='step', fill=False, lw=2)\n",
    "#density=False: If True, the histogram is normalized so that the area under the histogram integrates to 1. If False, the histogram represents the count of occurrences in each bin.\n",
    "#'bar': Traditional bar histogram (default)\n",
    "plt.xlabel('Rel. MMFF Energy (kcal/mol)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('RDKit-ETKDG')\n",
    "plt.grid(False)\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"rel_MMFF_energies-count_histogram\", bbox_inches='tight', pad_inches=0.04, transparent = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1fc8ae-38d5-49a4-8cae-a34775a7cbeb",
   "metadata": {
    "papermill": {
     "duration": 0.007366,
     "end_time": "2025-05-22T18:14:58.906945",
     "exception": false,
     "start_time": "2025-05-22T18:14:58.899579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 4: Calculating RMSD Matrix**\n",
    "\n",
    "Using Open Babel obrms command to calculate the Root Mean Square Deviation (RMSD) between the feasiable geometries present in an SDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e1781-89fe-471f-bb82-bb845f9b5f16",
   "metadata": {
    "papermill": {
     "duration": 572.250247,
     "end_time": "2025-05-22T18:24:31.164512",
     "exception": false,
     "start_time": "2025-05-22T18:14:58.914265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Run obrms on the concatenated sdf file of conformers with feasible geometries to compute RMSD matrix\n",
    "calculate_rmsd(feasible_geometries_sdf,pairwise_RMSDs_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf060db-6d6c-4f87-b3ea-29ef96009664",
   "metadata": {
    "papermill": {
     "duration": 0.226032,
     "end_time": "2025-05-22T18:24:31.398347",
     "exception": false,
     "start_time": "2025-05-22T18:24:31.172315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from scipy.spatial.distance import squareform, is_valid_dm\n",
    "\n",
    "### Read the pairwise RMSD matrix from the output of obrms; it is supposed to be a hollow, asymmetric matrix\n",
    "rmsd_matrix_DF: pd.DataFrame = pd.read_csv(pairwise_RMSDs_dat, header=None, index_col=0)\n",
    "\n",
    "### Convert the pairwise RMSD matrix into a numpy float-type 2D array\n",
    "rmsd_matrix: np.ndarray = rmsd_matrix_DF.to_numpy(dtype=float)\n",
    "\n",
    "### Round the matrix elements to two decimal places to avoid possible asymmetry in the matrix due to insignificant numerical errors\n",
    "rmsd_matrix_2DP: np.ndarray  = np.round(rmsd_matrix, 2)\n",
    "\n",
    "# Force the matrix to be symmetric\n",
    "rmsd_matrix_2DP = (rmsd_matrix_2DP + rmsd_matrix_2DP.T) / 2\n",
    "\n",
    "# Check if the matrix is symmetric\n",
    "if not is_valid_dm(rmsd_matrix_2DP, throw=False):\n",
    "    raise ValueError(\"The provided RMSD matrix is not symmetric even after rounding and forcing symmetry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851cc88-7371-4439-b0c8-04ce6504eece",
   "metadata": {
    "papermill": {
     "duration": 0.275405,
     "end_time": "2025-05-22T18:24:31.681643",
     "exception": false,
     "start_time": "2025-05-22T18:24:31.406238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Convert the the pairwise distance matrix to its condensed form; write the pairwise RMSDs from the condensed matrix into a CSV file\n",
    "from scipy.spatial.distance import squareform\n",
    "condensed_matrix: np.ndarray  = squareform(rmsd_matrix_2DP)\n",
    "pairwise_RMSDs_DF: pd.DataFrame = pd.DataFrame(condensed_matrix)\n",
    "pairwise_RMSDs_DF.to_csv(pairwise_RMSDs_csv, header=['pairwise_RMSD'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85816e3-82a2-4bba-b80b-8cb6a53c4b82",
   "metadata": {
    "papermill": {
     "duration": 0.249853,
     "end_time": "2025-05-22T18:24:31.939389",
     "exception": false,
     "start_time": "2025-05-22T18:24:31.689536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Plot the distribution of pairwise RMSDs\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "### Plot the histograms\n",
    "plt.hist(condensed_matrix, bins=8, density=True, color='black', fill=False, lw=2)\n",
    "\n",
    "### Format the axes\n",
    "plt.xlabel(r'RMSD ($\\AA)$')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Pairwise RMSDs')\n",
    "plt.grid(False)\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"pairwise_rmsd_distribution-PD.png\", bbox_inches='tight', pad_inches=0.04, transparent = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5227f49-febc-4c3b-a239-7159cd97fb55",
   "metadata": {
    "papermill": {
     "duration": 0.007615,
     "end_time": "2025-05-22T18:24:31.955216",
     "exception": false,
     "start_time": "2025-05-22T18:24:31.947601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 5: Hierarchical Cluster**\n",
    "\n",
    "Clustering the generated conformers into 20 clusters using hierarchical clustering with `ward` linkage method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3688fd-f0b5-43b1-8a3a-41e3ebec7969",
   "metadata": {
    "papermill": {
     "duration": 0.02699,
     "end_time": "2025-05-22T18:24:31.989806",
     "exception": false,
     "start_time": "2025-05-22T18:24:31.962816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Perform hierarchical clustering with 'ward' linkage method on the condensed version of pairwise distance matrix\n",
    "import scipy.cluster.hierarchy as sch\n",
    "linkage_matrix_ward: np.ndarray = sch.linkage(condensed_matrix, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### A few settings to export the image of the plot\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "### Plot the dendrogram to visualize the hierarchical clustering structure\n",
    "sch.dendrogram(linkage_matrix_ward, no_labels=True)\n",
    "plt.title('Dendrogram with Ward Linkage Method')\n",
    "plt.xlabel('Conformers')\n",
    "plt.ylabel('Distance')\n",
    "#plt.xticks(np.arange(0, 1000, 200))\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"hierarchical_clustering_dendogram-ward.png\", bbox_inches='tight', pad_inches=0.04, transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f04fd",
   "metadata": {
    "papermill": {
     "duration": 1.350715,
     "end_time": "2025-05-22T18:24:33.348233",
     "exception": false,
     "start_time": "2025-05-22T18:24:31.997518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### A few settings to export the image of the plot\n",
    "# plt.style.use('~/matplotlib_templates/single_column.mplstyle')\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "### Determine the optimal number of clusters using silhouette score; the original pairwise RMSD matrix must be used for this\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "## Calculate silhouette score for different numbers of clusters\n",
    "sil_scores = []\n",
    "range_n_clusters = list(range(2, 101))     # Try different numbers of clusters\n",
    "for n_clusters in range_n_clusters:\n",
    "    cluster_labels = fcluster(linkage_matrix_ward, n_clusters, criterion='maxclust')\n",
    "    cluster_counts = Counter(cluster_labels)\n",
    "    # print(cluster_counts)\n",
    "    \n",
    "    # Check if the clustering resulted in more than one cluster\n",
    "    if len(cluster_counts) > 1:\n",
    "        sil_score = silhouette_score(rmsd_matrix_2DP, cluster_labels, metric='precomputed')\n",
    "        sil_scores.append(sil_score)\n",
    "    else:\n",
    "        sil_scores.append(float('-inf'))  # Append a very low score if there's only one cluster    \n",
    "\n",
    "\n",
    "## Plot the Silhouette scores\n",
    "plt.plot(range_n_clusters, sil_scores, marker='o', color='black', fillstyle='none', ms=2, lw=2)\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Ward Linkage\")\n",
    "plt.axis([-5, 105, -0.05, 1.05])\n",
    "plt.xticks([0, 25, 50, 75, 100])\n",
    "plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "### Show the plot\n",
    "plt.show()\n",
    "\n",
    "### Save figure\n",
    "fig.savefig(\"silhouette_score_vs_num_clust-ward.png\", bbox_inches='tight', pad_inches=0.04, transparent = False)\n",
    "\n",
    "## Find the optimal number of clusters based on the maximum value of silhouette score and printing it\n",
    "max_sil_score = np.max(sil_scores)\n",
    "optimal_clusters = range_n_clusters[np.argmax(sil_scores)]\n",
    "print(f\"The optimal number of clusters is {optimal_clusters} with a silhouette score of {max_sil_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae62551-a2a0-4c22-87c3-134bbf204b69",
   "metadata": {
    "papermill": {
     "duration": 0.01789,
     "end_time": "2025-05-22T18:24:33.374764",
     "exception": false,
     "start_time": "2025-05-22T18:24:33.356874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "num_clusters = 5 if optimal_clusters > 5 else optimal_clusters\n",
    "\n",
    "## For each conformer, assign the cluster label to which it belongs\n",
    "cluster_labels: np.ndarray = fcluster(linkage_matrix_ward, num_clusters, criterion='maxclust')\n",
    "\n",
    "## Create an empty dictionary to store the cluster sets\n",
    "clusters: Dict[int, List[int]] = {i: [] for i in range(1, num_clusters + 1)}\n",
    "\n",
    "## Assign each cluster label to the respective cluster set\n",
    "for index, label in enumerate(cluster_labels):\n",
    "    clusters[label].append(index)     # Store the indices instead of raw data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16848016-bf7b-433e-be19-52d32e64231a",
   "metadata": {
    "papermill": {
     "duration": 0.007983,
     "end_time": "2025-05-22T18:24:33.390778",
     "exception": false,
     "start_time": "2025-05-22T18:24:33.382795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 6: Identifying Cluster Representative**\n",
    "\n",
    "Identifying the minimum energy conformer within each cluster as its representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38530063-2a90-4be7-a1f3-37adf6831120",
   "metadata": {
    "papermill": {
     "duration": 0.020593,
     "end_time": "2025-05-22T18:24:33.419348",
     "exception": false,
     "start_time": "2025-05-22T18:24:33.398755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Identify the minimum energy conformer within each cluster as its representative\n",
    "\n",
    "## Loop over all the cluster sets\n",
    "cluster_reps_list: List[pd.DataFrame] = []\n",
    "\n",
    "for clust_label, clust_elements in clusters.items():\n",
    "    if len(clust_elements)!=0:\n",
    "        clust_DF: pd.DataFrame = rel_energy_DF.loc[clust_elements]     # Extract the relative energies of the cluster elements into a dataframe\n",
    "        min_energy_index: int = clust_DF['rel_energy_in_kcalpermol'].idxmin()     # Find the row index correspoding to the minimum relative energy conformer within the cluster \n",
    "        min_energy_DF: pd.DataFrame= clust_DF.loc[[min_energy_index]]     # Isolate the repesentative conformer's relative energy into a dataframe\n",
    "        min_energy_DF['cluster_id'] = clust_label     # Add the 'cluster ID' information to the above dataframe\n",
    "        # print(min_energy_DF)\n",
    "        cluster_reps_list.append(min_energy_DF)     # Append the dataframe corresponding to each cluster representative into a list of dataframes\n",
    "\n",
    "## Concatenate the dataframes of all cluster representatives into a single dataframe\n",
    "cluster_reps_DF: pd.DataFrame = pd.concat(cluster_reps_list, ignore_index=True)\n",
    "\n",
    "## Sort the cluster respresentatives samples by 'conformer_id' and save the sorted dataframe to a csv file\n",
    "sorted_cluster_reps_DF: pd.DataFrame = cluster_reps_DF.sort_values(by='conformer_id', ascending=True)\n",
    "sorted_cluster_reps_DF.to_csv(cluster_reps_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89aa89-9c42-4721-99a7-10b0504d2774",
   "metadata": {
    "papermill": {
     "duration": 0.396981,
     "end_time": "2025-05-22T18:24:33.824411",
     "exception": false,
     "start_time": "2025-05-22T18:24:33.427430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "###  Write the coordinates of cluster representative conformers to SDF files.\n",
    "write_cluster_representatives(opt_conf_sdf,cluster_reps_dir,cluster_reps_sdf,sorted_cluster_reps_DF,cluster_reps_DF,cluster_rep_prefix,conf_extension)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03831e5-e21a-43b6-ac7c-f46d3555d109",
   "metadata": {
    "papermill": {
     "duration": 0.008241,
     "end_time": "2025-05-22T18:24:33.841394",
     "exception": false,
     "start_time": "2025-05-22T18:24:33.833153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Step 7: Calculating the Minimum RMSD**\n",
    "\n",
    "Calculating the min rmsd between refrence conformer and cluster representatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae270329-ece7-4d41-b8cb-b5597838cfea",
   "metadata": {
    "papermill": {
     "duration": 0.008381,
     "end_time": "2025-05-22T18:24:33.860683",
     "exception": false,
     "start_time": "2025-05-22T18:24:33.852302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# calculating the min rmsd between refrence conformer and cluster representatives\n",
    "result: float = calculate_min_rmsd(f\"../{ref_confo_path}\",cluster_reps_sdf)\n",
    "print(f\"Min RMSD 20 Clusters: {result}\")\n",
    "\n",
    "# Append the result to the text file\n",
    "with open('outputs.txt', 'a') as file:\n",
    "    file.write(f'Min_RMSD_20_cluster : {result}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6978d0c",
   "metadata": {
    "papermill": {
     "duration": 0.008521,
     "end_time": "2025-05-22T18:24:33.877540",
     "exception": false,
     "start_time": "2025-05-22T18:24:33.869019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 8: Geometry optimization of neutral conformers using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61ffef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python /app/dft_main.py DFT {cluster_reps_dir} {dielectric_value} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7d5b9-6e34-42e0-866b-1135a2938ceb",
   "metadata": {
    "papermill": {
     "duration": 0.749688,
     "end_time": "2025-05-22T18:47:45.887938",
     "exception": false,
     "start_time": "2025-05-22T18:47:45.138250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 9: Geometry optimization of charged conformers using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basis and XC\n",
    "basis_sets = ['aug-cc-pVDZ']\n",
    "xc_functionals = ['M06-2X']  # Add more if needed\n",
    "\n",
    "for basis in basis_sets:\n",
    "        for xc in xc_functionals:\n",
    "             # Sanitize names for filename safety\n",
    "            basis_tag = basis.replace(\"(\", \"\").replace(\")\", \"\").replace(\"*\", \"\").replace(\"+\", \"\").replace(\"/\", \"-\").replace(\" \", \"\")\n",
    "            xc_tag = xc.replace(\"(\", \"\").replace(\")\", \"\").replace(\"*\", \"\").replace(\"+\", \"\").replace(\"/\", \"-\").replace(\" \", \"\")\n",
    "\n",
    "# Get list of SDF files\n",
    "sdf_files = sorted(glob.glob(os.path.join(cluster_reps_dir, \"*.sdf\")))\n",
    "\n",
    "# Loop over each SDF file\n",
    "for sdf_path in sdf_files:\n",
    "    sdf_filename = os.path.basename(sdf_path)\n",
    "    sdf_stem = os.path.splitext(sdf_filename)[0]  # Remove .sdf extension\n",
    "\n",
    "    for basis in basis_sets:\n",
    "        for xc in xc_functionals:\n",
    "            \n",
    "            # Output file names\n",
    "            new_filename = f\"{sdf_stem}_{basis_tag}_{xc_tag}.sdf\"\n",
    "            new_filepath = os.path.join(cluster_reps_dir, new_filename)\n",
    "            shutil.copy(sdf_path, new_filepath)\n",
    "            print(\"Renamed output will be:\", new_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define base paths\n",
    "base_dir = f\"/app/{output_dir}/cluster_rep_conformers\"\n",
    "treated_dir = os.path.join(base_dir, \"treated\")\n",
    "\n",
    "# Run the external Python script\n",
    "subprocess.run([\n",
    "    \"python\",\n",
    "    \"/app/ionization_tool_with_ranking/main.py\",\n",
    "    base_dir\n",
    "], check=True)\n",
    "\n",
    "# Move all .sdf files from treated/ to base_dir\n",
    "sdf_files = glob.glob(os.path.join(treated_dir, \"*.sdf\"))\n",
    "for file_path in sdf_files:\n",
    "    shutil.move(file_path, base_dir)\n",
    "\n",
    "# Remove the treated directory\n",
    "shutil.rmtree(treated_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /app/dft_main.py DFT_DEPROTO {cluster_reps_dir} {dielectric_value} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa20541-9f07-495a-82ec-352a68c06a68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Step 10: Accumulating DFT data and Writing the CSV for pKa Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6634319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_xyz_files(folder_path):\n",
    "    \"\"\"\n",
    "    Creates a pandas DataFrame from .xyz files in a given folder,\n",
    "    extracting Basis, XC, and energy.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the .xyz files.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with 'file name', 'Basis', 'XC', and 'energy' columns.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Updated Regex to match the filename pattern and capture Basis and XC\n",
    "    # This regex is more robust to handle basis sets and XC functionals\n",
    "    # that may contain hyphens, numbers, or specific characters.\n",
    "    # It assumes the structure is:\n",
    "    # rep_of_cluster_N_BASIS_XC_optional_treatment.xyz\n",
    "    filename_pattern = re.compile(\n",
    "        r\"rep_of_cluster_\\d+_([a-zA-Z0-9\\-]+)_([a-zA-Z0-9\\-]+)(?:_deprotonated|_protonated)?\\.xyz\"\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".xyz\"):\n",
    "            match = filename_pattern.match(filename)\n",
    "            if match:\n",
    "                basis = match.group(1)\n",
    "                xc = match.group(2)\n",
    "\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        f.readline()  # Skip the first line (number of atoms)\n",
    "                        energy_line = f.readline().strip()\n",
    "\n",
    "                        energy = None\n",
    "                        try:\n",
    "                            energy = float(energy_line)\n",
    "                        except ValueError:\n",
    "                            energy_match = re.search(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", energy_line)\n",
    "                            if energy_match:\n",
    "                                energy = float(energy_match.group(0))\n",
    "                            else:\n",
    "                                print(f\"Could not extract energy from line: '{energy_line}' in file: {filename}\")\n",
    "\n",
    "                        data.append({\n",
    "                            'file name': filename,\n",
    "                            'Basis': basis,\n",
    "                            'XC': xc,\n",
    "                            'energy': energy\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"Filename pattern did not match for: {filename}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# --- How to use the function ---\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_dataframe_from_xyz_files(cluster_reps_dir)\n",
    "\n",
    "\n",
    "df.head(15)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---\n",
    "# Step 1: Extract the Common Prefix\n",
    "def extract_prefix(filename):\n",
    "    match = re.match(r'(rep_of_cluster_\\d+_aug-cc-pVDZ_M06-2X)', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return filename\n",
    "\n",
    "df['prefix'] = df['file name'].apply(extract_prefix)\n",
    "\n",
    "# ---\n",
    "# Step 2: Group and Process to Assign Custom Names, including Basis and XC\n",
    "\n",
    "output_rows = []\n",
    "for prefix, group in df.groupby('prefix'):\n",
    "    row_dict = {'Prefix': prefix}\n",
    "    \n",
    "    # Get Basis and XC from the first row of the group (they should be constant within the group)\n",
    "    # Using .iloc[0] is safe here because each group will have at least one row\n",
    "    row_dict['Basis'] = group['Basis'].iloc[0]\n",
    "    row_dict['XC'] = group['XC'].iloc[0]\n",
    "\n",
    "    # Initialize placeholders for the new columns\n",
    "    row_dict['Filename_original'] = None\n",
    "    row_dict['Energy_original'] = None\n",
    "    row_dict['Filename_acid_treated'] = None\n",
    "    row_dict['Energy_acid_treated'] = None\n",
    "    row_dict['Filename_base_treated'] = None\n",
    "    row_dict['Energy_base_treated'] = None\n",
    "\n",
    "\n",
    "    for _, entry in group.iterrows():\n",
    "        filename = entry['file name']\n",
    "        energy = entry['energy']\n",
    "\n",
    "        if '_deprotonated' in filename:\n",
    "            row_dict['Filename_deprotonated'] = filename\n",
    "            row_dict['Energy_deprotonated'] = energy\n",
    "        elif '_protonated' in filename:\n",
    "            row_dict['Filename_protonated'] = filename\n",
    "            row_dict['Energy_protonated'] = energy\n",
    "        else:\n",
    "            # Assuming files without _acid_treat or _base_treat are the 'original'\n",
    "            row_dict['Filename_original'] = filename\n",
    "            row_dict['Energy_original'] = energy\n",
    "            \n",
    "    output_rows.append(row_dict)\n",
    "\n",
    "result_df = pd.DataFrame(output_rows)\n",
    "\n",
    "# Reorder columns for better readability\n",
    "# Ensure all these columns exist in result_df before attempting to reorder\n",
    "desired_columns = ['Prefix', 'Basis', 'XC',\n",
    "                   'Filename_original', 'Energy_original',\n",
    "                   'Filename_deprotonated', 'Energy_deprotonated',\n",
    "                   'Filename_protonated', 'Energy_protonated']\n",
    "\n",
    "# Filter for only the columns that actually exist in result_df to avoid errors\n",
    "existing_columns = [col for col in desired_columns if col in result_df.columns]\n",
    "result_df = result_df[existing_columns]\n",
    "\n",
    "\n",
    "#print\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02983554-0efb-4ad7-afba-4d8755aac0d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Step 11: Data analysis and pKa Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e7287-08f9-4e46-9d38-587dd275e0ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df['E_proton (acidic)']=pKa_EXP*1.36574 +(result_df['Energy_original'] -result_df['Energy_deprotonated'])\n",
    "if 'Energy_protonated' in result_df.columns:\n",
    "    result_df['E_proton (basic)']=pKa_EXP*1.36574 -(result_df['Energy_original'] -result_df['Energy_protonated'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734caa6-deb6-45d4-835e-874293e3fb28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = 298  # Temperature in Kelvin\n",
    "k_B = 0.0019872041  # Boltzmann constant in kcal/mol·K\n",
    "\n",
    "E_shifted = result_df['Energy_original'] - result_df['Energy_original'].min()  # shift energies so lowest is 0\n",
    "weights = np.exp(-E_shifted / (k_B * T))\n",
    "\n",
    "#Boltzmann Probabilities\n",
    "result_df['Weights'] = weights / np.sum(weights)\n",
    "\n",
    "if 'Energy_deprotonated' in result_df.columns and 'Energy_protonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original', 'Energy_deprotonated','E_proton (acidic)','Energy_protonated', 'E_proton (basic)', 'Weights' ]]\n",
    "\n",
    "elif 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original', 'Energy_deprotonated','E_proton (acidic)','Weights' ]]\n",
    "\n",
    "elif 'Energy_protonated' in result_df.columns:\n",
    "    result_df=result_df[['Prefix', 'Basis', 'XC', 'Energy_original','Energy_protonated', 'E_proton (basic)', 'Weights' ]]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28756c-022d-4b65-a0ba-860d2dc6899a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pKa Calculation weighted avg\n",
    "if 'Energy_deprotonated' in result_df.columns:\n",
    "    result_df.loc[:, 'pka (acidic)'] = 0.7322 * (\n",
    "        E_avg_proton -\n",
    "        (result_df['Energy_original'] - result_df['Energy_deprotonated'])\n",
    "    )\n",
    "    pka_cal_acidic = sum(result_df['pka (acidic)'] * result_df['Weights'])\n",
    "\n",
    "if 'Energy_protonated' in result_df.columns:\n",
    "    result_df.loc[:, 'pka (basic)'] = 0.7322 * (\n",
    "        E_avg_proton + (result_df['Energy_original'] - result_df['Energy_protonated'])\n",
    "    )\n",
    "    pka_cal_basic = sum(result_df['pka (basic)'] * result_df['Weights'])\n",
    "\n",
    "result_df.to_csv(\"cluster_rep_conformers/conformerwise_pka.csv\", index=False)\n",
    "\n",
    "# Print appropriate values\n",
    "if 'pka_cal_acidic' in locals():\n",
    "    print(\"pKa_calculated (acidic, weighted average):\", pka_cal_acidic)\n",
    "if 'pka_cal_basic' in locals():\n",
    "    print(\"pKa_calculated (basic, weighted average):\", pka_cal_basic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c4a18-19f4-4238-bbb7-6fdf509467fb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Capture the end time\n",
    "end_time: float = time.time()\n",
    "\n",
    "# Calculate the execution time in seconds\n",
    "execution_time_seconds: float = end_time - start_time\n",
    "\n",
    "# Convert the execution time to minutes\n",
    "execution_time_minutes: int = execution_time_seconds // 60\n",
    "\n",
    "with open('outputs.txt', 'a') as file:\n",
    "    file.write(f'Execution_time : {execution_time_minutes}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72594f20-7a0f-483d-949e-dac9c3a77b96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Molecule\": [inp_smiles],\n",
    "    \"Solvent (ε)\": [dielectric_value],\n",
    "    \"# Conformers\": [len(cluster_reps_DF)],\n",
    "    \"pKa (Exp)\": [pKa_EXP],\n",
    "}\n",
    "\n",
    "try:\n",
    "    data[\"pKa_cal_acidic (weighted avg)\"] = [round(pka_cal_acidic, 1)]\n",
    "except NameError:\n",
    "    data[\"pKa_cal_acidic (weighted avg)\"] = [np.nan]\n",
    "try:\n",
    "    data[\"pKa_cal_basic (weighted avg)\"]= [round(pka_cal_basic, 1)]\n",
    "except NameError:\n",
    "    data[\"pKa_cal_basic (weighted avg)\"]= [np.nan]\n",
    "\n",
    "df_final = pd.DataFrame(data)\n",
    "df_final.to_csv(\"cluster_rep_conformers/Final_cal_pka.csv\",index=False)\n",
    "\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0e582-a425-4d22-8846-8a358791921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0071b-3b59-45dd-a852-1ea91ff88892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981f53e-f8ef-454c-9b16-7e24058f2903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc307be-de9e-46c4-a1c2-165eacd46cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2006.300544,
   "end_time": "2025-05-22T18:47:55.689251",
   "environment_variables": {},
   "exception": true,
   "input_path": "full_pipeline_pka_ovh_2.ipynb",
   "output_path": "full_pipeline_pka_ovh_2_output.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T18:14:29.388707",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
